{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key\n",
    "data = Original dataset, no changes\n",
    "\n",
    "data_1 = Edited for modeling; Dropped id, member_id, emp_title, url, desc, title, zip_code (because last two digits missing), create dummy variables for categorical data, convert variables with dates to distance in months to January 2017 (for consistency and use in modeling)\n",
    "\n",
    "data_10 = Drop variables with over 95% missing, fill in rest with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Miles Strother\\Desktop\\Kaggle\\LCD\\loan.csv\", low_memory=False)\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop variables not needed for modeling\n",
    "data_1 = data.drop(['id', 'member_id', 'emp_title', 'url', 'desc', 'title', 'zip_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split categorical data into dummy variables\n",
    "categories = ['term', 'grade', 'sub_grade', 'emp_length', 'home_ownership', 'verification_status', 'loan_status', 'pymnt_plan', 'purpose', 'addr_state', 'initial_list_status', 'application_type', 'verification_status_joint']\n",
    "data_dummies = pd.get_dummies(data_1[categories])\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop categorical variables and add dummy variables to data_1\n",
    "data_2 = data_1.drop(data_1[categories], axis=1)\n",
    "data_3 = pd.concat([data_2, data_dummies], axis=1, join_axes=[data_1.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to a change variable with dates to distance in months to January 2017\n",
    "date_variables = ['issue_d', 'earliest_cr_line', 'last_pymnt_d', 'next_pymnt_d', 'last_credit_pull_d']\n",
    "def date_func(dataframe, date_variable, new_list):\n",
    "    for x in date_variable:\n",
    "        if x[:3] == 'Jan':\n",
    "            y,z = x.split('-')\n",
    "            a = y.replace(y[:3], '12')\n",
    "            b = ((2016 - int(z[-5:]))*12)\n",
    "            c = int(a) + b\n",
    "            new_list.append(c)\n",
    "        elif x[:3] == 'Feb':\n",
    "            y,z = x.split('-')\n",
    "            a = y.replace(y[:3], '11')\n",
    "            b = ((2016 - int(z[-5:]))*12)\n",
    "            c = int(a) + b\n",
    "            new_list.append(c)\n",
    "        elif x[:3] == 'Mar':\n",
    "            y,z = x.split('-')\n",
    "            a = y.replace(y[:3], '10')\n",
    "            b = ((2016 - int(z[-5:]))*12)\n",
    "            c = int(a) + b\n",
    "            new_list.append(c)\n",
    "        elif x[:3] == 'Apr':\n",
    "            y,z = x.split('-')\n",
    "            a = y.replace(y[:3], '9')\n",
    "            b = ((2016 - int(z[-5:]))*12)\n",
    "            c = int(a) + b\n",
    "            new_list.append(c)\n",
    "        elif x[:3] == 'May':\n",
    "            y,z = x.split('-')\n",
    "            a = y.replace(y[:3], '8')\n",
    "            b = ((2016 - int(z[-5:]))*12)\n",
    "            c = int(a) + b\n",
    "            new_list.append(c)\n",
    "        elif x[:3] == 'Jun':\n",
    "            y,z = x.split('-')\n",
    "            a = y.replace(y[:3], '7')\n",
    "            b = ((2016 - int(z[-5:]))*12)\n",
    "            c = int(a) + b\n",
    "            new_list.append(c)\n",
    "        elif x[:3] == 'Jul':\n",
    "            y,z = x.split('-')\n",
    "            a = y.replace(y[:3], '6')\n",
    "            b = ((2016 - int(z[-5:]))*12)\n",
    "            c = int(a) + b\n",
    "            new_list.append(c)\n",
    "        elif x[:3] == 'Aug':\n",
    "            y,z = x.split('-')\n",
    "            a = y.replace(y[:3], '5')\n",
    "            b = ((2016 - int(z[-5:]))*12)\n",
    "            c = int(a) + b\n",
    "            new_list.append(c)\n",
    "        elif x[:3] == 'Sep':\n",
    "            y,z = x.split('-')\n",
    "            a = y.replace(y[:3], '4')\n",
    "            b = ((2016 - int(z[-5:]))*12)\n",
    "            c = int(a) + b\n",
    "            new_list.append(c)\n",
    "        elif x[:3] == 'Oct':\n",
    "            y,z = x.split('-')\n",
    "            a = y.replace(y[:3], '3')\n",
    "            b = ((2016 - int(z[-5:]))*12)\n",
    "            c = int(a) + b\n",
    "            new_list.append(c)\n",
    "        elif x[:3] == 'Nov':\n",
    "            y,z = x.split('-')\n",
    "            a = y.replace(y[:3], '2')\n",
    "            b = ((2016 - int(z[-5:]))*12)\n",
    "            c = int(a) + b\n",
    "            new_list.append(c)\n",
    "        elif x[:3] == 'Dec':\n",
    "            y,z = x.split('-')\n",
    "            a = y.replace(y[:3], '1')\n",
    "            b = ((2016 - int(z[-5:]))*12)\n",
    "            c = int(a) + b\n",
    "            new_list.append(c)\n",
    "        else:\n",
    "            a = x.replace(x, '0')\n",
    "            new_list.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change variables with dates to distance in months to January 2017\n",
    "issue_list = []\n",
    "data_3['issue_d'] = data_3['issue_d'].replace(np.nan, ' ', regex=True)\n",
    "date_func(data_3, data_3['issue_d'], issue_list)\n",
    "data_3['issue_date'] = np.asarray(issue_list)\n",
    "data_4 = data_3.drop(['issue_d'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_list = []\n",
    "data_4['earliest_cr_line'] = data_4['earliest_cr_line'].replace(np.nan, ' ', regex=True)\n",
    "date_func(data_4, data_4['earliest_cr_line'], cr_list)\n",
    "data_4['earliest_credit_line'] = np.asarray(cr_list)\n",
    "data_5 = data_4.drop(['earliest_cr_line'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_list = []\n",
    "data_5['last_pymnt_d'] = data_5['last_pymnt_d'].replace(np.nan, ' ', regex=True)\n",
    "date_func(data_5, data_5['last_pymnt_d'], last_list)\n",
    "data_5['last_payment'] = np.asarray(last_list)\n",
    "data_6 = data_5.drop(['last_pymnt_d'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_list = []\n",
    "data_6['next_pymnt_d'] = data_6['next_pymnt_d'].replace(np.nan, ' ', regex=True)\n",
    "date_func(data_6, data_6['next_pymnt_d'], next_list)\n",
    "data_6['next_payment'] = np.asarray(next_list)\n",
    "data_7 = data_6.drop(['next_pymnt_d'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_credit_list = []\n",
    "data_7['last_credit_pull_d'] = data_7['last_credit_pull_d'].replace(np.nan, ' ', regex=True)\n",
    "date_func(data_7, data_7['last_credit_pull_d'], last_credit_list)\n",
    "data_7['last_credit'] = np.asarray(last_credit_list)\n",
    "data_8 = data_7.drop(['last_credit_pull_d'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all variables with more than 90% missing values\n",
    "large_missing = []\n",
    "for column in data_8:\n",
    "    h = data_8[column]\n",
    "    count = h.isnull().sum()\n",
    "    if (887379 - count)/887379 <= .05:\n",
    "        large_missing.append(column)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_9 = data_8.drop(large_missing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_10 = data_9.fillna(data_9.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data_1, row=\"sex\", col=\"race\", margin_titles=True)\n",
    "g.map(plt.hist, \"hoursperweek\", color=\"steelblue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(count) is int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4['earliest_cr_line'] = data_4['earliest_cr_line'].replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4['earliest_cr_line'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data_4['earliest_cr_line']\n",
    "n.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(issue_date).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_variables = ['issue_d', 'earliest_cr_line', 'last_pymnt_d', 'next_pymnt_d', 'last_credit_pull_d']\n",
    "issue_date = []\n",
    "for x in data_3['issue_d']:\n",
    "    if x[:3] == 'Jan' or 'Feb':\n",
    "        y = x.replace(x[:3], '1' or '2')\n",
    "        issue_date.append(y)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(issue_date).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See which variables have a high number of missing values\n",
    "for column in data_1:\n",
    "    count = np.count_nonzero(data_1[column])\n",
    "    print(count, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See which variables have than 90% missing\n",
    "data_description = pd.read_excel(r\"C:\\Users\\Miles Strother\\Desktop\\Kaggle\\LCD\\LCDataDictionary.xlsx\")\n",
    "data_description.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
